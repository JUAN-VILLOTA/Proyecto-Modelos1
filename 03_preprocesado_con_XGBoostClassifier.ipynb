{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Predicción de Rendimiento con XGBoost.\n",
        "\n",
        "Este notebook implementa un clasificador XGBoost para predecir el rendimiento académico de estudiantes basándose en datos de las pruebas Saber Pro de Colombia.\n",
        "\n",
        "## Objetivo:\n",
        "Predecir el `RENDIMIENTO_GLOBAL` de estudiantes en 4 categorías:\n",
        "- Alto\n",
        "- Medio-Alto\n",
        "- Medio-Bajo\n",
        "- Bajo\n",
        "\n",
        "---\n",
        "\n",
        "## Paso 1: Cargar credenciales de Kaggle\n",
        "\n",
        "Primero, subimos el archivo `kaggle.json` que contiene las credenciales de la API de Kaggle para poder descargar los datos de la competencia."
      ],
      "metadata": {
        "id": "AL-svyoGCOxb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blp9xQhFuHkm"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Descargar datos de Kaggle:\n",
        "\n",
        "Configuramos las credenciales de Kaggle y descargamos los datasets de la competencia:\n",
        "- `train. csv`: Datos de entrenamiento con la variable objetivo\n",
        "- `test.csv`: Datos de prueba sin la variable objetivo\n",
        "- `submission_example.csv`: Ejemplo del formato de envío\n",
        "\n",
        "El comando `wc *.csv` muestra el número de líneas, palabras y bytes de cada archivo."
      ],
      "metadata": {
        "id": "zDyFmuzrCPgX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '. '\n",
        "\n",
        "!chmod 600 kaggle.json\n",
        "! kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n",
        "! unzip *.zip > /dev/null\n",
        "!wc *.csv"
      ],
      "metadata": {
        "id": "rqHzmYNluRct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importar librerías necesarias:\n",
        "\n",
        "Importamos las bibliotecas que utilizaremos:\n",
        "- **pandas**: Manipulación de datos\n",
        "- **numpy**: Operaciones numéricas\n",
        "- **sklearn**: Herramientas de machine learning (división de datos, encoding, métricas)\n",
        "- **xgboost**: Algoritmo de gradient boosting para clasificación"
      ],
      "metadata": {
        "id": "bvPFYFcoCSFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "e6wyfkHZCRwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paso 4: Definir la clase clasificadora\n",
        "\n",
        "*   Elemento de la lista\n",
        "*   Elemento de la lista\n",
        "\n",
        "\n",
        "\n",
        "### `StudentPerformanceXGBoostClassifier`\n",
        "\n",
        "Esta clase encapsula todo el pipeline de machine learning:\n",
        "\n",
        "###**Métodos de limpieza:**\n",
        "- `clean_periodo()`: Separa PERIODO_ACADEMICO en AÑO y PERIODO\n",
        "- `clean_internet()`: Consolida columnas duplicadas de internet\n",
        "- `clean_estrato()`: Normaliza valores de estrato socioeconómico (\"Estrato 3\" → 3)\n",
        "- `clean_valormatricula()`: Convierte rangos de matrícula a valores ordinales (1-7)\n",
        "- `clean_horastrabajo()`: Convierte rangos de horas trabajadas a valores ordinales (0-4)\n",
        "- `clean_educacion()`: Mapea niveles educativos a escala ordinal (0-9)\n",
        "- `clean_binary()`: Convierte Si/No a 1/0\n",
        "\n",
        "### **Feature Engineering:**\n",
        "- `feature_engineering()`: Crea nuevas características:\n",
        "  - Variables binarias para bienes del hogar\n",
        "  - Promedio, máximo, mínimo y diferencia de educación de padres\n",
        "  - Score de bienes del hogar (ponderado)\n",
        "  - Score socioeconómico integrado\n",
        "  - Estadísticos de los indicadores (promedio, max, min)\n",
        "\n",
        "###**Encoding:**\n",
        "- `encode_categorical()`: Codifica variables categóricas sin orden lógico usando LabelEncoder\n",
        "\n",
        "### **Pipeline:**\n",
        "- `preprocess_data()`: Ejecuta todo el preprocesamiento en orden\n",
        "- `train_model()`: Entrena el modelo XGBoost con hiperparámetros optimizados\n",
        "- `evaluate()`: Evalúa el modelo y muestra métricas\n",
        "- `save_predictions()`: Genera archivo de submission para Kaggle"
      ],
      "metadata": {
        "id": "iVDEBmapCTAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StudentPerformanceXGBoostClassifier:\n",
        "    def __init__(self):\n",
        "        self.label_encoders = {}\n",
        "        self.model = None\n",
        "        self.target_column = 'RENDIMIENTO_GLOBAL'\n",
        "\n",
        "    #limpieza\n",
        "    def clean_periodo(self, df):\n",
        "        df['AÑO'] = df['PERIODO_ACADEMICO'].astype(str). str[:4]. astype(int)\n",
        "        df['PERIODO'] = df['PERIODO_ACADEMICO'].astype(str).str[4:].astype(int)\n",
        "        df. drop(columns=['PERIODO_ACADEMICO'], inplace=True)\n",
        "        return df\n",
        "\n",
        "    def clean_internet(self, df):\n",
        "        if 'F_TIENEINTERNET. 1' in df.columns:\n",
        "            df['F_TIENEINTERNET'] = df['F_TIENEINTERNET.1'].fillna(df['F_TIENEINTERNET'])\n",
        "            df.drop(columns=['F_TIENEINTERNET.1'], inplace=True)\n",
        "        return df\n",
        "\n",
        "    def clean_estrato(self, x):\n",
        "        if pd.isna(x):\n",
        "            return 0\n",
        "        x = str(x).lower(). strip()\n",
        "        x = x.replace(\"estrato\", \"\").strip()\n",
        "        return int(x) if x.isdigit() else 0\n",
        "\n",
        "    def clean_valormatricula(self, x):\n",
        "        if pd.isna(x):\n",
        "            return 0\n",
        "\n",
        "        matricula_map = {\n",
        "            'menos de 500 mil': 1,\n",
        "            'entre 500 mil y menos de 1 millón': 2,\n",
        "            'entre 1 millón y menos de 2. 5 millones': 3,\n",
        "            'entre 2.5 millones y menos de 4 millones': 4,\n",
        "            'entre 4 millones y menos de 5. 5 millones': 5,\n",
        "            'entre 5.5 millones y menos de 7 millones': 6,\n",
        "            'más de 7 millones': 7,\n",
        "            'no pagó matrícula': 0\n",
        "        }\n",
        "\n",
        "        x_lower = str(x).lower(). strip()\n",
        "        return matricula_map.get(x_lower, 0)\n",
        "\n",
        "    def clean_horastrabajo(self, x):\n",
        "        if pd.isna(x):\n",
        "            return 0\n",
        "\n",
        "        x_str = str(x).lower().strip()\n",
        "\n",
        "        if x_str == '0':\n",
        "            return 0\n",
        "        elif 'menos de 10' in x_str:\n",
        "            return 1\n",
        "        elif 'entre 11 y 20' in x_str:\n",
        "            return 2\n",
        "        elif 'entre 21 y 30' in x_str:\n",
        "            return 3\n",
        "        elif 'más de 30' in x_str or 'mas de 30' in x_str:\n",
        "            return 4\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def clean_educacion(self, x):\n",
        "        if pd.isna(x):\n",
        "            return 2\n",
        "\n",
        "        edu_map = {\n",
        "            'ninguno': 0,\n",
        "            'primaria incompleta': 1,\n",
        "            'primaria completa': 2,\n",
        "            'secundaria (bachillerato) incompleta': 3,\n",
        "            'secundaria (bachillerato) completa': 4,\n",
        "            'técnica o tecnológica incompleta': 5,\n",
        "            'técnica o tecnológica completa': 6,\n",
        "            'educación profesional incompleta': 7,\n",
        "            'educación profesional completa': 8,\n",
        "            'postgrado': 9,\n",
        "            'no sabe': 2,\n",
        "            'no aplica': 2\n",
        "        }\n",
        "\n",
        "        x_lower = str(x).lower().strip()\n",
        "        return edu_map.get(x_lower, 2)\n",
        "\n",
        "    def clean_binary(self, x):\n",
        "        if pd.isna(x):\n",
        "            return 0\n",
        "        x_str = str(x).lower(). strip()\n",
        "        return 1 if x_str in ['si', 'sí', 's', 'y'] else 0\n",
        "\n",
        "\n",
        "    #feature engineering\n",
        "    def feature_engineering(self, df):\n",
        "\n",
        "        # Limpiar columna duplicada de internet PRIMERO\n",
        "        df = self.clean_internet(df)\n",
        "\n",
        "        # convertir variables binarias\n",
        "        df['INTERNET_BIN'] = df['F_TIENEINTERNET'].apply(self.clean_binary)\n",
        "        df['LAVADORA_BIN'] = df['F_TIENELAVADORA'].apply(self. clean_binary)\n",
        "        df['AUTOMOVIL_BIN'] = df['F_TIENEAUTOMOVIL'].apply(self.clean_binary)\n",
        "        df['COMPUTADOR_BIN'] = df['F_TIENECOMPUTADOR'].apply(self.clean_binary)\n",
        "        df['PAGOMATRICULA_BIN'] = df['E_PAGOMATRICULAPROPIO'].apply(self.clean_binary)\n",
        "        df['PRIVADO_LIBERTAD_BIN'] = df['E_PRIVADO_LIBERTAD'].apply(lambda x: 1 if str(x).upper() == 'S' else 0)\n",
        "\n",
        "        # Convertir variables numéricas ordinales\n",
        "        df['F_ESTRATOVIVIENDA_NUM'] = df['F_ESTRATOVIVIENDA'].apply(self.clean_estrato)\n",
        "        df['E_VALORMATRICULAUNIVERSIDAD_NUM'] = df['E_VALORMATRICULAUNIVERSIDAD'].apply(self.clean_valormatricula)\n",
        "        df['E_HORASSEMANATRABAJA_NUM'] = df['E_HORASSEMANATRABAJA']. apply(self.clean_horastrabajo)\n",
        "        df['F_EDUCACIONPADRE_NUM'] = df['F_EDUCACIONPADRE'].apply(self.clean_educacion)\n",
        "        df['F_EDUCACIONMADRE_NUM'] = df['F_EDUCACIONMADRE'].apply(self.clean_educacion)\n",
        "\n",
        "        # features derivadas de educación\n",
        "        df['FAMI_EDUCACION_PROMEDIO'] = (df['F_EDUCACIONPADRE_NUM'] + df['F_EDUCACIONMADRE_NUM']) / 2\n",
        "        df['FAMI_EDUCACION_MAX'] = df[['F_EDUCACIONPADRE_NUM', 'F_EDUCACIONMADRE_NUM']].max(axis=1)\n",
        "        df['FAMI_EDUCACION_MIN'] = df[['F_EDUCACIONPADRE_NUM', 'F_EDUCACIONMADRE_NUM']].min(axis=1)\n",
        "        df['FAMI_EDUCACION_DIFERENCIA'] = abs(df['F_EDUCACIONPADRE_NUM'] - df['F_EDUCACIONMADRE_NUM'])\n",
        "\n",
        "        # Score de bienes del hogar\n",
        "        df['SCORE_BIENES'] = (\n",
        "            df['LAVADORA_BIN'] * 0.2 +\n",
        "            df['AUTOMOVIL_BIN'] * 0.4 +\n",
        "            df['COMPUTADOR_BIN'] * 0.3 +\n",
        "            df['INTERNET_BIN'] * 0. 1\n",
        "        )\n",
        "\n",
        "        # Score socioeconómico integrado\n",
        "        df['SCORE_SOCIOECONOMICO'] = (\n",
        "            df['F_ESTRATOVIVIENDA_NUM'] * 0.3 +\n",
        "            df['E_VALORMATRICULAUNIVERSIDAD_NUM'] * 0.3 +\n",
        "            df['SCORE_BIENES'] * 0.4\n",
        "        )\n",
        "\n",
        "        # Usar indicadores si existen\n",
        "        if 'INDICADOR_1' in df.columns:\n",
        "            df['INDICADOR_PROMEDIO'] = df[['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']].mean(axis=1)\n",
        "            df['INDICADOR_MAX'] = df[['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']]. max(axis=1)\n",
        "            df['INDICADOR_MIN'] = df[['INDICADOR_1', 'INDICADOR_2', 'INDICADOR_3', 'INDICADOR_4']].min(axis=1)\n",
        "\n",
        "        return df\n",
        "\n",
        "    #Encoding\n",
        "    def encode_categorical(self, df, is_training=True):\n",
        "\n",
        "        categorical_columns = ['E_PRGM_ACADEMICO', 'E_PRGM_DEPARTAMENTO']\n",
        "\n",
        "        for col in categorical_columns:\n",
        "            if col in df. columns:\n",
        "                if is_training:\n",
        "                    le = LabelEncoder()\n",
        "                    df[col] = le.fit_transform(df[col]. astype(str))\n",
        "                    self.label_encoders[col] = le\n",
        "                else:\n",
        "                    le = self.label_encoders[col]\n",
        "                    df[col] = df[col].astype(str). apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
        "                    df[col] = le.transform(df[col])\n",
        "\n",
        "        return df\n",
        "\n",
        "    #preprocesado\n",
        "    def preprocess_data(self, df, is_training=True):\n",
        "\n",
        "        df = df.copy()\n",
        "        ids = df['ID']. copy()\n",
        "\n",
        "        df = self.clean_periodo(df)\n",
        "        df = self.feature_engineering(df)\n",
        "        df = self.encode_categorical(df, is_training=is_training)\n",
        "\n",
        "        #eliminar columnas originales ya procesadas\n",
        "        columns_to_drop = [\n",
        "            'F_TIENEINTERNET', 'F_TIENELAVADORA', 'F_TIENEAUTOMOVIL',\n",
        "            'F_TIENECOMPUTADOR', 'E_PAGOMATRICULAPROPIO', 'E_PRIVADO_LIBERTAD',\n",
        "            'F_ESTRATOVIVIENDA', 'E_VALORMATRICULAUNIVERSIDAD', 'E_HORASSEMANATRABAJA',\n",
        "            'F_EDUCACIONPADRE', 'F_EDUCACIONMADRE'\n",
        "        ]\n",
        "\n",
        "        df. drop(columns=[col for col in columns_to_drop if col in df.columns], inplace=True)\n",
        "\n",
        "        #Verificar que no queden columnas object\n",
        "        object_cols = df.select_dtypes(include=['object']).columns. tolist()\n",
        "        if object_cols and self.target_column in object_cols:\n",
        "            object_cols.remove(self.target_column)\n",
        "\n",
        "        if object_cols:\n",
        "            df. drop(columns=object_cols, inplace=True, errors='ignore')\n",
        "\n",
        "        #separar target y features\n",
        "        if is_training and self.target_column in df.columns:\n",
        "            y = df[self.target_column]\n",
        "            X = df.drop(columns=[self.target_column, 'ID'])\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "            return X_train, X_test, y_train, y_test\n",
        "        else:\n",
        "            df.drop(columns=['ID'], inplace=True, errors='ignore')\n",
        "            return df, ids\n",
        "\n",
        "    #Entrenamiento parametros\n",
        "    def train_model(self, X_train, y_train):\n",
        "\n",
        "        if y_train.dtype == 'object':\n",
        "            self.target_encoder = LabelEncoder()\n",
        "            y_train_encoded = self.target_encoder. fit_transform(y_train)\n",
        "        else:\n",
        "            y_train_encoded = y_train\n",
        "\n",
        "        self.model = xgb.XGBClassifier(\n",
        "            n_estimators=450,\n",
        "            learning_rate=0.04,\n",
        "            max_depth=9,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8,\n",
        "            objective='multi:softmax',\n",
        "            num_class=len(np.unique(y_train_encoded)),\n",
        "            tree_method='hist',\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        self.model.fit(X_train, y_train_encoded)\n",
        "        print(\"-->>Entrenamiento completado<<--\")\n",
        "\n",
        "    #Evaluacion y reportes\n",
        "    def evaluate(self, X_test, y_test):\n",
        "\n",
        "        if y_test.dtype == 'object':\n",
        "            y_test_encoded = self.target_encoder.transform(y_test)\n",
        "        else:\n",
        "            y_test_encoded = y_test\n",
        "\n",
        "        preds_encoded = self.model.predict(X_test)\n",
        "\n",
        "        if hasattr(self, 'target_encoder'):\n",
        "            preds = self.target_encoder. inverse_transform(preds_encoded)\n",
        "            y_test_original = y_test\n",
        "        else:\n",
        "            preds = preds_encoded\n",
        "            y_test_original = y_test\n",
        "\n",
        "        print(\"Reporte de Clasificación:\")\n",
        "        print(classification_report(y_test_original, preds))\n",
        "        print(\"Matriz de Confusión:\")\n",
        "        print(confusion_matrix(y_test_original, preds))\n",
        "\n",
        "        return preds\n",
        "\n",
        "    #Guardar archivo\n",
        "    def save_predictions(self, df_test, filename='submission. csv'):\n",
        "\n",
        "        df_test_processed, ids = self.preprocess_data(df_test, is_training=False)\n",
        "        preds_encoded = self.model.predict(df_test_processed)\n",
        "\n",
        "        if hasattr(self, 'target_encoder'):\n",
        "            preds = self.target_encoder.inverse_transform(preds_encoded)\n",
        "        else:\n",
        "            preds = preds_encoded\n",
        "\n",
        "        submission = pd.DataFrame({\"ID\": ids, \"RENDIMIENTO_GLOBAL\": preds})\n",
        "        submission. to_csv(filename, index=False)\n",
        "        print(f\"Archivo guardado como: {filename}\")\n",
        "\n",
        "        return submission"
      ],
      "metadata": {
        "id": "nYFt1wWv1XCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cargar los datos\n",
        "\n",
        "Cargamos los archivos CSV descargados de Kaggle:\n",
        "- **train.csv**: Dataset de entrenamiento (~692,500 registros)\n",
        "- **test.csv**: Dataset de prueba (~296,786 registros)"
      ],
      "metadata": {
        "id": "load-data-description"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar datos\n",
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "j6_HK9E_zXaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inicializar el clasificador\n",
        "\n",
        "Creamos una instancia de la clase `StudentPerformanceXGBoostClassifier` que contiene todo el pipeline de ML."
      ],
      "metadata": {
        "id": "init-classifier-description"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = StudentPerformanceXGBoostClassifier()"
      ],
      "metadata": {
        "id": "biwtdKlhzfhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocesar datos y entrenar modelo\n",
        "\n",
        "### Preprocesamiento:\n",
        "1.  Limpia y normaliza todas las columnas\n",
        "2. Crea features derivadas (scores socioeconómicos, promedios de educación, etc.)\n",
        "3. Codifica variables categóricas\n",
        "4. Divide datos en train (80%) y test (20%) con estratificación\n",
        "\n",
        "### Entrenamiento:\n",
        "Entrena un modelo XGBoost con los siguientes hiperparámetros:\n",
        "- **n_estimators**: 450 árboles\n",
        "- **learning_rate**: 0.04\n",
        "- **max_depth**: 9 niveles por árbol\n",
        "- **subsample**: 0. 8 (usa 80% de datos por árbol)\n",
        "- **colsample_bytree**: 0.8 (usa 80% de features por árbol)"
      ],
      "metadata": {
        "id": "train-description"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesar y entrenar\n",
        "X_train, X_test, y_train, y_test = clf.preprocess_data(df_train, is_training=True)\n",
        "clf.train_model(X_train, y_train)"
      ],
      "metadata": {
        "id": "lvlvHwWPzf-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluar el modelo\n",
        "\n",
        "Evaluamos el rendimiento del modelo en el conjunto de validación (20% de train).\n",
        "\n",
        "### Métricas mostradas:\n",
        "- **Precision**: De las predicciones de cada clase, cuántas fueron correctas\n",
        "- **Recall**: De todos los casos reales de cada clase, cuántos se detectaron\n",
        "- **F1-score**: Media armónica entre precision y recall\n",
        "- **Support**: Número de casos reales de cada clase\n",
        "- **Matriz de confusión**: Detalle de predicciones correctas e incorrectas por clase\n",
        "\n",
        "**Interpretación:** Un accuracy del ~43% indica que el modelo tiene dificultad para distinguir entre las 4 clases, especialmente entre las categorías intermedias (medio-alto y medio-bajo)."
      ],
      "metadata": {
        "id": "evaluate-description"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar\n",
        "clf.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "id": "YaZwuhDuzhvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generar predicciones para Kaggle\n",
        "\n",
        "Aplicamos el modelo entrenado sobre el dataset de test y generamos el archivo de submission.\n",
        "\n",
        "### Proceso:\n",
        "1.  Preprocesa el dataset de test usando el mismo pipeline que train\n",
        "2.  Genera predicciones para cada estudiante\n",
        "3. Crea un DataFrame con formato Kaggle:\n",
        "   - **ID**: Identificador del estudiante\n",
        "   - **RENDIMIENTO_GLOBAL**: Predicción (alto, medio-alto, medio-bajo, bajo)\n",
        "4. Guarda como `my_submission.csv`\n",
        "\n",
        "###Resultado:\n",
        "Archivo listo para subir a la competencia de Kaggle con 296,786 predicciones."
      ],
      "metadata": {
        "id": "submission-description"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predecir en test\n",
        "clf.save_predictions(df_test, 'my_submission.csv')"
      ],
      "metadata": {
        "id": "z2_jfFh_zk9w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}